{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3468b688-7165-4ce3-9545-f469901c0f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(model_dict, dates, ticker_symbols):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    pred_base_range = model_dict[\"pred_base_range\"]\n",
    "    \n",
    "    # Check if the model was trained for all the provided ticker symbols:\n",
    "    ticker_symbols = set(ticker_symbols)\n",
    "    tickers_to_remove = []\n",
    "    for ticker in ticker_symbols:\n",
    "        if ticker not in model_dict[\"ticker_symbols\"]:\n",
    "            print(f\"WARN: model {model_dict['name']} was not trained to predict prices for {ticker}!\")\n",
    "            tickers_to_remove.append(ticker)\n",
    "    \n",
    "    for ticker in tickers_to_remove:\n",
    "            ticker_symbols.remove(ticker)\n",
    "            \n",
    "    # Check if the date ranges are outside the range which were used for training:\n",
    "    dates = set(dates)\n",
    "    dates_to_remove = []\n",
    "    for date in dates:\n",
    "        if (date > model_dict[\"start_date\"]) and (date < model_dict[\"end_date\"]):\n",
    "            print(f\"WARN: model {model_dict['name']}  was trained with the date {date} and therefore no predictions for that date can be made!\")\n",
    "            dates_to_remove.append(date)\n",
    "    for date in dates_to_remove:\n",
    "        dates.remove(date)\n",
    "            \n",
    "    # Initialize a result dictionary\n",
    "    result = {}\n",
    "    for ticker in ticker_symbols:\n",
    "        result[ticker] = {}\n",
    "        # sort dates so there is no need to predict a day twice\n",
    "        for target_date in dates:\n",
    "            print(f\"Predicting {ticker} price for {target_date}\") \n",
    "            start_date = datetime.today() - timedelta(days=pred_base_range)\n",
    "            # if the date is to far in the future, multiple iterations are necessary\n",
    "            \n",
    "            delta = target_date - datetime.today() # as timedelta to predict\n",
    "\n",
    "            # If no Adj close is available for today, today also needs to be predicted\n",
    "            for i in range(1, delta.days + 2):\n",
    "                day = datetime.today() + timedelta(days=i)\n",
    "                print(day)\n",
    "            \n",
    "            \n",
    "            available_data = get_stock_data(ticker_symbols = [ticker], start_date =  start_date, end_date = datetime.today(), date_index = True, columns=\"all\")\n",
    "            formated_data = tickers_as_columns(available_data)\n",
    "            filtered_data = formated_data.filter([ticker])\n",
    "            dataset = filtered_data.values\n",
    "            scaler, y_test = scale_data(dataset)\n",
    "            print(y_test.shape)\n",
    "            \n",
    "            prediction = 0\n",
    "            result[ticker][target_date] = prediction\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ab7e09-c496-4c3d-8415-059c92b370a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes a subset of the dataframe which is still a dataframe with 2D (len,1)\n",
    "filtered_data = formated_data.filter(['GOOG'])\n",
    "# I assume this creates a Pandas Series object which is just 1D\n",
    "# close_data = formated_data['GOOG']\n",
    "# 2. Convert the data into array for easy evaluation\n",
    "dataset = filtered_data.values\n",
    "\n",
    "pred_base_range = 60\n",
    "\n",
    "scaler, scaled_dataset = scale_data(dataset)\n",
    "x_train, y_train, x_test, y_test, training_data_len = train_test_split(scaled_dataset, days = pred_base_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924e61db-d10d-4730-afaa-0aecf5dd001e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tickers_as_columns(data_dict, column=\"Adj Close\"):\n",
    "        '''\n",
    "        This method reformats a dictionary generated by the \"get_stock_data\"-method.\n",
    "        The structure before is the following\n",
    "        dict{\n",
    "                stock1: [[High], [Low], [Close] ...],\n",
    "                stock2: [[High], [Low], [Close] ...],\n",
    "                ...\n",
    "        }\n",
    "\n",
    "        The method creates a dataframe which keeps the dates as the index, but adds a column for each stock based on a chosen value. The default value is \"Adj Close\".\n",
    "        '''\n",
    "        columns = []\n",
    "        column_names = []\n",
    "        for key in data_dict:\n",
    "            column_names.append(key)\n",
    "            columns.append(data_dict[key][column])\n",
    "        df = pd.DataFrame(columns, index = column_names)\n",
    "        return df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe0ce0b-9e1b-4be5-814b-2f0ffdfdb9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def plot_approximation(filtered_data, training_data_len, predictions):\n",
    "#     train = filtered_data[:training_data_len]\n",
    "#     valid = filtered_data[training_data_len:].copy()\n",
    "#     valid.loc[:,'Predictions'] = predictions\n",
    "\n",
    "#     plt.title('Model')\n",
    "#     plt.xlabel('Date')\n",
    "#     plt.ylabel('Close')\n",
    "\n",
    "#     plt.plot(train['GOOG'])\n",
    "#     plt.plot(valid[['GOOG', 'Predictions']])\n",
    "\n",
    "#     plt.legend(['Train', 'Val', 'Predictions'], loc='lower right')\n",
    "\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec41ed3-93ec-405f-a2a9-19c748191fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_model_dict(model_name, model_dir = \"./models/\"):\n",
    "#     with open(model_dir + model_name + \"_metadata.obj\", 'rb') as file:\n",
    "#         # Call load method to deserialze\n",
    "#         model_dict = pickle.load(file)\n",
    "\n",
    "#     model_dict[\"model\"] = load_model(model_name, model_dir)\n",
    "#     return model_dict\n",
    "\n",
    "# def load_model(model_name, model_dir = \"./models/\"):\n",
    "#     model = tf.keras.models.load_model(model_dir + model_name + \"_model\")\n",
    "#     return model\n",
    "\n",
    "# def store_model_pickle(name, model, model_dir = \"./models/\"):\n",
    "#     try:\n",
    "#         model_params = model.get_params()\n",
    "#         fileObj = open(f'{model_dir}{name}_params.obj', 'wb')\n",
    "#         pickle.dump(model_params,fileObj)\n",
    "#         fileObj.close()\n",
    "#     except:\n",
    "#         pass\n",
    "#     fileObj = open(f'{name}.obj', 'wb')\n",
    "#     pickle.dump(model,fileObj)\n",
    "#     fileObj.close()\n",
    "    \n",
    "# def store_model_keras(name, model, model_dir = \"./models/\"):\n",
    "#     model.save(f'{model_dir}{name}', save_format=\"h5\" )  # creates a HDF5 file 'my_model.h5'\n",
    "\n",
    "\n",
    "#     def save_model_dict(model_dict, model_dir = \"./models/\"):\n",
    "#         model = model_dict[\"model\"]\n",
    "#         # First store the model using the Keras function because the model cannot be stored with pickle (weakref-error)\n",
    "#         store_model_keras(model_dict[\"name\"] + \"_model\", model)\n",
    "#         model_dict[\"model\"] = None\n",
    "#         fileObj = open(model_dir + model_dict[\"name\"] + \"_metadata.obj\", 'wb')\n",
    "#         pickle.dump(model_dict,fileObj)\n",
    "#         model_dict[\"model\"] = model\n",
    "\n",
    "#         fileObj.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4118989-6eb0-4e22-aabe-640319630e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_model(ticker, name, start_date, end_date = datetime.today(), pred_base_range = 60):\n",
    "    # Create dictionary to store the model and its metadata\n",
    "    model_dict = {}\n",
    "    model_dict[\"name\"] = name\n",
    "    model_dict[\"ticker\"] = ticker\n",
    "    model_dict[\"start_date\"] = start_date\n",
    "    model_dict[\"end_date\"] = end_date\n",
    "    model_dict[\"pred_base_range\"] = pred_base_range\n",
    "    \n",
    "    # Get the data, rescale it and divide it into training and test set\n",
    "    df = get_adj_close_df([ticker], start_date, end_date = datetime.today())\n",
    "    df_values = df.values\n",
    "    scaler, scaled_dataset = scale_data(df_values)\n",
    "    x_train, y_train, x_test, y_test, training_data_len = train_test_split(scaled_dataset, days = pred_base_range)\n",
    "    \n",
    "    # Train a model with the data\n",
    "    \n",
    "    \n",
    "    model = get_model(input_shape = x_train.shape[1])\n",
    "    model.fit(x_train, y_train, batch_size=1, epochs=1)\n",
    "    model_dict[\"model\"] = model\n",
    "    \n",
    "    return model_dict\n",
    "    #store_model_keras(\"first_lstm\", first_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9961553-0405-4017-97b7-3ad7e606ef2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_timerange_from_now(include_today = True, n_days = 5, weekends = False):\n",
    "    '''\n",
    "    Returns a list of all future dates from now\n",
    "    '''\n",
    "    day_list = list()\n",
    "    if include_today:\n",
    "        i = 0\n",
    "    else:\n",
    "        i = 1\n",
    "    while len(day_list) < n_days:\n",
    "        next_day = datetime.now() + timedelta(days=i)\n",
    "        i = i + 1\n",
    "        # Consider if the day is on the weekend\n",
    "        if not weekends:\n",
    "            if next_day.weekday() < 5:\n",
    "                day_list.append(next_day)\n",
    "        else:\n",
    "            day_list.append(next_day)\n",
    "    return day_list\n",
    "\n",
    "def extend_df(df, predictions, new_timerange = None):\n",
    "    '''\n",
    "    This methods takes a df of values and appends the predicted values to the dataframe. The new timerange is used as index.\n",
    "    '''\n",
    "    column_name = df.columns[0]\n",
    "    if new_timerange == None:\n",
    "        new_timerange = create_timerange_from_now()\n",
    "    date_index = pd.DatetimeIndex(new_timerange).normalize()\n",
    "    new_df = pd.DataFrame(data = predictions, index = date_index, columns = [column_name])\n",
    "    combined_df = pd.concat([df, new_df])\n",
    "    return combined_df        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
