{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7917757-a0f6-4199-baca-a089a734781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import normal libraries\n",
    "import pandas_datareader as pdr\n",
    "from datetime import datetime as dt\n",
    "import os\n",
    "\n",
    "# Import own libraries\n",
    "from data_api.init_db import return_engine\n",
    "from data_api.db import get_formated_price_data_sets, get_ticker_by_ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5658c21-37c7-43e1-8c18-c94e66aedcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the data\n",
    "\n",
    "# Define the data paths\n",
    "current_dir = os.getcwd()\n",
    "database_dir = os.path.join(current_dir, \"data\")\n",
    "db_filename = \"database.db\"\n",
    "model_dir = os.path.join(current_dir, \"data/models\")\n",
    "scaler_dir = os.path.join(current_dir, \"data/scalers\")\n",
    "# Setup the database engine\n",
    "engine = return_engine(database_dir, db_filename=db_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea3b22f-cf57-4077-9125-591ce8a0175c",
   "metadata": {},
   "source": [
    "# Problem Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbca84b-5812-4e5a-b5c6-e6a70d2bbd6c",
   "metadata": {},
   "source": [
    "From the Yahoo Finance API, we get the 6 different values for each day. High price, low price, open price, close price, adjusted close price and volume. The 5 price data variables are all closely linked together, and only the adjusted close price reflects additional events like divident payouts or stock splits. Therefore, we only consider the adjusted close price (now referred to as \"price\") and the volume for our models. \n",
    "\n",
    "Our goal is to predict future prices based on the past prices and the past volume. We can use the price/volume data of multiple stocks to predict the price/volume data of those multiple stocks to make use of the information hidden in the dependence of the development in those different assets. The problem is, that we have indeed a long timerange of past data, but we do not know anything about future prices (yet). Therefore, we need to split the past data into small sections and consider the earlier part of that section as the past data and the later part as the future. Therefore we can create many training sets of past/future data combinations to use for our training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445b0eae-2b2c-4487-ba76-c2568f58f800",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654b68e5-96b1-4b0a-a2db-137d8213bad4",
   "metadata": {},
   "source": [
    "We need to define a useful metric or multiple metrics to evaluate the performance of our model and to compare different models with different hyperparameters. The goal of our model is to predict continious values, therefore we have a regression problem. For regression problems, we can use root mean squared error (RMSE) as a metric to optimize our model for. This metric weights larger deviations from the expected results more than lower deviations, but still has a value on the same scale as the output data.\n",
    "\n",
    "- https://keras.io/api/metrics/\n",
    "- https://machinelearningmastery.com/custom-metrics-deep-learning-keras-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae66498-3d20-4eeb-92df-c39b1d0b675b",
   "metadata": {},
   "source": [
    "# EDA (Exploratory data analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93135ef9-7cdc-4fee-8a9b-57604ea10e19",
   "metadata": {},
   "source": [
    "When we check the data, we encounter one problem: We do not have price and volume data available for arbitrary dates for each asset. For weekends and holidays, there is usually no trading occuring on stock exchanges and therefore no price is determined. These dates without price data vary between different assets, depending on which exchanges they are listed and in which jurisdiction the exchanges are located. For some assets, like Bitcoin, there is nevertheless price data available for all days because there is less regulation about the exchanges and the cryptocurrencies can be easily traded completly digital. Additionally, there is no price data available before the asset was available. In the case of a publicly traded company, this is usually the IPO.\n",
    "To train a model with different assets, we are therefore likely facing missing values for some assets on some dates. For the first, problem, namely missing days for holidays/weekends, we have two options:\n",
    "- Drop the data for a specific date, when no price data is missing for at least one asset\n",
    "- Fill the missing prices with the average price of the days before and after\n",
    "\n",
    "In the first case, we would potentially reduce our dataset significant, in case we have many different assets from many differen exchanges/jurisdictions. Therefore we take the second option and fill up the missing prices as mentioned.\n",
    "\n",
    "To handle the second problem, namely missing asset prices because the asset was not publicly traded, it is more difficult to handle this. We can either:\n",
    "- Limit the oldest date to the date when, the last asset was available\n",
    "- Assume an average price of the asset for the time before it was available\n",
    "- Assume a price of 0 before the asset was available\n",
    "- Assume the price of the first day when the asset was available\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bfe1e0d8-c774-4f5e-8e05-27c94a609f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=dt(2020,1,1)\n",
    "end=dt.today()\n",
    "tickers = [\"GOOG\", \"AAPL\", \"BTC-USD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d56845ce-1f17-4e42-a9f4-bb12a6e5bae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_formatted_train_data(engine, ticker_ids, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Loads the required raw data from the database\n",
    "    \"\"\"\n",
    "    # Get the data from the API\n",
    "    # df = api.get_adj_close_df(tickers, start_date, end_date, date_index=False)\n",
    "\n",
    "    # Get the data from the database\n",
    "    df = get_formated_price_data_sets(engine, ticker_ids, start_date, end_date)\n",
    "\n",
    "    # Extract the dates from the dataframe\n",
    "    dates = df[\"timestamp\"]\n",
    "    df.drop([\"timestamp\"], axis=1, inplace=True)\n",
    "\n",
    "    # New dataframe with only training data\n",
    "    df_for_training = df.astype(float)\n",
    "    print(f\"Data columns used to build model: {df.columns.values}\")\n",
    "    return df_for_training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "348c54e8-b55f-46d1-af7f-c0a390343835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 5, 4]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers_to_ticker_ids(engine, tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5da19c94-2e65-46a1-b1ea-34d759ef90ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_tickers_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m train_data \u001b[38;5;241m=\u001b[39m load_formatted_train_data(\n\u001b[0;32m----> 3\u001b[0m                 engine, \u001b[43mmodel_tickers_ids\u001b[49m, start_date, end_date)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_tickers_ids' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "train_data = load_formatted_train_data(\n",
    "                engine, model_tickers_ids, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91a42eea-5edc-44a1-b211-33b794c8df9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "twitter_df = pdr.data.DataReader(\"TWTR\", 'yahoo', start, end)\n",
    "tesla_df = pdr.data.DataReader(\"TSLA\", 'yahoo', start, end)\n",
    "btc_df = pdr.data.DataReader(\"BTC-USD\", 'yahoo', start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1aeda1ad-e87a-4dd8-8138-21fb64a074a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2020-01-01', '2020-01-04', '2020-01-05', '2020-01-11',\n",
       "               '2020-01-12', '2020-01-18', '2020-01-19', '2020-01-20',\n",
       "               '2020-01-25', '2020-01-26',\n",
       "               ...\n",
       "               '2022-03-13', '2022-03-19', '2022-03-20', '2022-03-26',\n",
       "               '2022-03-27', '2022-04-02', '2022-04-03', '2022-04-09',\n",
       "               '2022-04-10', '2022-04-15'],\n",
       "              dtype='datetime64[ns]', name='Date', length=259, freq=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btc_df.index.difference(twitter_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6d9a6e-f62c-4844-ac1e-3dcf0e19b0fa",
   "metadata": {},
   "source": [
    "# Modelling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1586e77-55cb-43da-b845-3da936c7bf12",
   "metadata": {},
   "source": [
    "To model our problem based on time series data, we need to recognize that the sequence of the data is also containing a lot of information and need to be used in the model. For this type of problem, a long short-term memory (LSTM) model is usually the best fit. With this model, the sequence data is processed in sequence and the data contained in the earlier sequence steps is kept during the whole processs and has an influence on the prediction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83a0f35-cfe1-48ad-996e-67fabe8ff9ae",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034d8274-d806-4111-9e44-779e0a94193e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7adc5f3-d3ae-441c-af25-137149b1b9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space  {\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac306ab5-cce3-4d29-b476-44b509d272d1",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b4857e-be83-4549-b2ac-72f13f1539e2",
   "metadata": {},
   "source": [
    "# Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdd07c8-a667-44b6-bb7d-415d758031de",
   "metadata": {},
   "source": [
    "# Conclusion/Reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8012306c-caeb-405e-ba24-05440d298942",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
